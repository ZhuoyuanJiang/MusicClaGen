{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the top of src/preprocess.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import ast  # To parse the multi_hot_label string if needed\n",
    "import logging\n",
    "from tqdm import tqdm # For progress bar: pip install tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "cwd = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(cwd, '../..')) # NOTE: remember to change if change the directory structure\n",
    "\n",
    "# Add project root to Python's module search path\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "import src.utils as utils  \n",
    "from src.utils import get_audio_path as get_audio_path \n",
    "import config # NOTE: need to check config to make sure all paths and parameters are correct\n",
    "\n",
    "\n",
    "# --- Setup Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Define Helper Function (or import from utils.py) ---\n",
    "# It's cleaner to put this in src/utils.py\n",
    "\n",
    "\n",
    "# this get_audio_path is exactly the same as the one in utils.py, I just copy it here to make understanding easier\n",
    "def get_audio_path(audio_dir, track_id):\n",
    "    \"\"\"Constructs the path to an FMA audio file.\"\"\"\n",
    "    tid_str = '{:06d}'.format(track_id)\n",
    "    return os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')\n",
    "\n",
    "def extract_mel_spectrogram(audio_path, params):\n",
    "    \"\"\"Loads audio, computes Log-Mel Spectrogram using parameters from config.\"\"\"\n",
    "    try:\n",
    "        # 1. Pull all preprocessing settings out of the params dict\n",
    "        sr                  = params[\"sample_rate\"]              \n",
    "        duration            = params[\"segment_duration_seconds\"] \n",
    "        samples_per_segment = params[\"samples_per_segment\"]      \n",
    "        n_fft               = params[\"n_fft\"]                    \n",
    "        hop_length          = params[\"hop_length\"]               \n",
    "        n_mels              = params[\"n_mels\"]                   \n",
    "\n",
    "        # 2. Load the audio file\n",
    "        #    - resamples to `sr`,  \n",
    "        #    - only reads up to `duration` seconds\n",
    "        y, loaded_sr = librosa.load(\n",
    "            audio_path,\n",
    "            sr=sr,\n",
    "            duration=duration\n",
    "        )\n",
    "\n",
    "        # 3. Pad if shorter than expected duration (librosa pads by default, but explicit is safer)\n",
    "        if len(y) < samples_per_segment:\n",
    "            # 3a. If too short, pad the end with zeros\n",
    "            y = np.pad(y, (0, samples_per_segment - len(y)))\n",
    "        elif len(y) > samples_per_segment:\n",
    "            # 3b. If too long (rare, but just in case), truncate\n",
    "            y = y[:samples_per_segment]\n",
    "\n",
    "        # 4. Compute the Mel spectrogram\n",
    "        melspectrogram = librosa.feature.melspectrogram(\n",
    "            y=y,\n",
    "            sr=sr,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            n_mels=n_mels\n",
    "        )\n",
    "\n",
    "        # 5. Convert power to decibel (log scale), normalizing by the max power\n",
    "        log_melspectrogram = librosa.power_to_db(\n",
    "            melspectrogram,\n",
    "            ref=np.max\n",
    "        )\n",
    "\n",
    "        # 6. Return the final 2D array (shape: [n_mels, time_frames])\n",
    "        return log_melspectrogram\n",
    "\n",
    "    except Exception as e:\n",
    "        # 7. If anything fails (file missing, decode error, etc.), log a warning...\n",
    "        logging.warning(\n",
    "            f\"Could not process file {os.path.basename(audio_path)}: {e}\"\n",
    "        )\n",
    "        # 8. ...and return None so downstream code can skip it gracefully\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhuoyuan/CSprojects/musicClaGen/data/processed/fma_features\n"
     ]
    }
   ],
   "source": [
    "print(config.FMA_FEATURES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Main Processing Logic ---\n",
    "\n",
    "def preprocess_audio_features():\n",
    "    \"\"\"\n",
    "    Extracts log-mel spectrogram features for each track in the small FMA subset\n",
    "    and writes them to disk, plus builds a CSV manifest linking features to labels.\n",
    "\n",
    "    Side effects (outputs on disk):\n",
    "      1. A directory of `.npy` files, one per track, in `config.FMA_FEATURES_DIR`.\n",
    "         - Filenames are `<track_id>.npy`\n",
    "         - Each file contains a 2D NumPy array of shape (n_mels, time_frames).\n",
    "      2. A CSV file named `final_feature_manifest.csv` in `config.PROCESSED_DATA_DIR`.\n",
    "         - Columns:\n",
    "           • track_id      – integer ID of the track\n",
    "           • feature_path  – relative path to the saved `.npy` file\n",
    "           • label_vector  – the multi-hot list of genre labels\n",
    "           • split         – which dataset split the track belongs to (train/val/test)\n",
    "\n",
    "    Mock up example of the manifest file:\n",
    "    | track_id | feature_path              | label_vector         | split |\n",
    "    |---------:|---------------------------|----------------------|:-----:|\n",
    "    |   123456 | data/features/123456.npy  | [0,1,0,0,1,…]        | train |\n",
    "    |   234567 | data/features/234567.npy  | [1,0,0,1,0,…]        | test  |\n",
    "    |    …     | …                         | …                    |  …    |\n",
    "\n",
    "\n",
    "\n",
    "    Workflow:\n",
    "      1. Load `small_subset_multihot.csv` (must exist in `PROCESSED_DATA_DIR`).\n",
    "      2. Parse the `multi_hot_label` strings back into Python lists.\n",
    "      3. Ensure output directory for features exists.\n",
    "      4. Loop over each track:\n",
    "         a. Check audio file path is valid.\n",
    "         b. Compute log-mel spectrogram via `extract_mel_spectrogram`.\n",
    "         c. If successful, save the array as `<track_id>.npy` and record its info.\n",
    "      5. After the loop, save all recorded entries into `final_feature_manifest.csv`.\n",
    "\n",
    "    Logging:\n",
    "      - INFO for major milestones (start/end, counts).\n",
    "      - WARNING for skipped tracks (missing files or failed extraction).\n",
    "      - ERROR for unrecoverable issues (failed file I/O or metadata parsing).\n",
    "\n",
    "    Returns:\n",
    "      None\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    logging.info(\"--- Starting Feature Extraction ---\")\n",
    "\n",
    "    # --- Load the final metadata with multi-hot labels ---\n",
    "    metadata_path = os.path.join(config.PROCESSED_DATA_DIR, 'small_subset_multihot.csv')\n",
    "    if not os.path.exists(metadata_path):\n",
    "        logging.error(f\"Metadata file not found: {metadata_path}. Run label processing first.\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"Loading metadata with multi-hot labels from {metadata_path}\")\n",
    "    try:\n",
    "        # Load the CSV, keeping track_id as index\n",
    "        metadata_df = pd.read_csv(metadata_path, index_col='track_id')\n",
    "\n",
    "        # --- CRITICAL: Parse the 'multi_hot_label' string back into a list/array ---\n",
    "        # The .to_csv likely saved the list as its string representation.\n",
    "        # We use ast.literal_eval to safely convert it back.\n",
    "        metadata_df['multi_hot_label'] = metadata_df['multi_hot_label'].apply(ast.literal_eval)\n",
    "        \n",
    "        \n",
    "        # Considering converting inner list to numpy array (if needed downstream), keep as list is fine too. so if want to convert, uncomment the following line.\n",
    "        # metadata_df['multi_hot_label'] = metadata_df['multi_hot_label'].apply(np.array)\n",
    "\n",
    "        logging.info(f\"Loaded and parsed metadata for {len(metadata_df)} tracks.\")\n",
    "        logging.info(\"Example parsed label vector:\")\n",
    "        # Display first element to check format\n",
    "        print(metadata_df['multi_hot_label'].iloc[0])\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load or parse metadata CSV '{metadata_path}': {e}\", exc_info=True)\n",
    "        return\n",
    "\n",
    "    # --- Create output directory for features ---\n",
    "    features_output_dir = config.FMA_FEATURES_DIR\n",
    "    os.makedirs(features_output_dir, exist_ok=True)\n",
    "    logging.info(f\"Ensured processed features directory exists: {features_output_dir}\")\n",
    "\n",
    "    # --- Loop, Extract, Save ---\n",
    "    manifest_data = [] # To store info for the final manifest file\n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    logging.info(f\"Starting feature extraction loop for {len(metadata_df)} tracks...\")\n",
    "    # Use tqdm for a progress bar in the terminal\n",
    "    for track_id, row in tqdm(metadata_df.iterrows(), total=len(metadata_df)):\n",
    "        audio_path = row['audio_path']\n",
    "        multi_hot_label = row['multi_hot_label'] # Now it's a list/array\n",
    "        split = row['split']\n",
    "\n",
    "        # Final check if audio path really exists\n",
    "        if not isinstance(audio_path, str) or not os.path.exists(audio_path):\n",
    "             logging.warning(f\"Audio path missing or invalid for track {track_id}: '{audio_path}'. Skipping.\")\n",
    "             error_count += 1\n",
    "             continue\n",
    "\n",
    "        # Extract features using the function defined earlier, this is the .npy file content\n",
    "        log_melspec = extract_mel_spectrogram(audio_path, config.PREPROCESSING_PARAMS)\n",
    "\n",
    "        if log_melspec is not None:\n",
    "            # Define path to save the feature file (.npy)\n",
    "            feature_filename = f\"{track_id}.npy\"\n",
    "            # Store relative path from project root in manifest for portability\n",
    "            relative_feature_path = os.path.join(os.path.relpath(features_output_dir, PROJECT_ROOT), feature_filename)\n",
    "            absolute_feature_path = os.path.join(features_output_dir, feature_filename)\n",
    "\n",
    "            # Save the feature array\n",
    "            try:\n",
    "                np.save(absolute_feature_path, log_melspec)\n",
    "\n",
    "                # Add entry to manifest list\n",
    "                manifest_data.append({\n",
    "                    'track_id': track_id,\n",
    "                    'feature_path': relative_feature_path, # Use relative path\n",
    "                    'label_vector': multi_hot_label,       # Store the actual list/vector\n",
    "                    'split': split\n",
    "                })\n",
    "                processed_count += 1\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to save feature for track {track_id} to {absolute_feature_path}: {e}\")\n",
    "                error_count += 1\n",
    "        else:\n",
    "            # Feature extraction failed (error already logged in the function)\n",
    "            error_count += 1\n",
    "\n",
    "    logging.info(\"Feature extraction loop finished.\")\n",
    "    logging.info(f\"Successfully processed and saved features for: {processed_count} tracks.\")\n",
    "    logging.info(f\"Errors/Skipped during feature extraction: {error_count} tracks.\")\n",
    "\n",
    "    # --- Save the final manifest ---\n",
    "    if not manifest_data:\n",
    "        logging.warning(\"No features were successfully processed. Manifest file will be empty.\")\n",
    "        return\n",
    "\n",
    "    manifest_df = pd.DataFrame(manifest_data)\n",
    "    # Reorder columns for clarity\n",
    "    manifest_df = manifest_df[['track_id', 'feature_path', 'label_vector', 'split']]\n",
    "\n",
    "    manifest_path = os.path.join(config.PROCESSED_DATA_DIR, 'final_feature_manifest.csv')\n",
    "    try:\n",
    "        # Save the manifest mapping track IDs to feature paths and labels\n",
    "        manifest_df.to_csv(manifest_path, index=False)\n",
    "        logging.info(f\"Saved final manifest file ({len(manifest_df)} entries) to {manifest_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save manifest file: {e}\", exc_info=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First draft! \n",
    "\n",
    "# To be deleted... It has errors... go to mel_specto_conversion_exploration copy.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicClaGen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
