{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully.\n",
      "DataFrame shape: (8000, 3)\n",
      "Columns: ['audio_path', 'multi_hot_label', 'split']\n",
      "\n",
      "Parsing multi_hot_label column...\n",
      "\n",
      "First 3 parsed values:\n",
      "1: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (type: <class 'list'>)\n",
      "2: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (type: <class 'list'>)\n",
      "3: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (type: <class 'list'>)\n",
      "\n",
      "Total number of labels across all tracks: 176000\n",
      "Average labels per track: 22.00\n",
      "\n",
      "Metadata processing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Functions to preprocess the .mp3 files into mel-spectrograms.\n",
    "\"\"\"\n",
    "\n",
    "# At the top of src/preprocess.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import re  # For parsing the multi_hot_label strings\n",
    "import logging\n",
    "from tqdm import tqdm # For progress bar: pip install tqdm\n",
    "\n",
    "import sys\n",
    "\n",
    "cwd = os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(cwd, '../..')) # NOTE: remember to change if change the directory structure\n",
    "\n",
    "# Add project root to Python's module search path\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "import src.utils as utils  \n",
    "from src.utils import get_audio_path as get_audio_path \n",
    "import config # NOTE: need to check config to make sure all paths and parameters are correct\n",
    "\n",
    "\n",
    "# --- Setup Logging ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Define Helper Function (or import from utils.py) ---\n",
    "def get_audio_path(audio_dir, track_id):\n",
    "    \"\"\"Constructs the path to an FMA audio file.\"\"\"\n",
    "    tid_str = '{:06d}'.format(track_id)\n",
    "    return os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')\n",
    "\n",
    "def parse_numpy_array_string(array_str):\n",
    "    \"\"\"\n",
    "    Parse strings like '[np.float32(1.0), np.float32(0.0), ...]' into a list of integers.\n",
    "    This is needed because ast.literal_eval cannot handle 'np.float32()' in the string.\n",
    "    \"\"\"\n",
    "    if not isinstance(array_str, str):\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Extract all the float values using regular expressions\n",
    "        float_matches = re.findall(r'np\\.float32\\((\\d+\\.\\d+)\\)', array_str)\n",
    "        \n",
    "        # Convert matches to integers (1.0 -> 1, 0.0 -> 0)\n",
    "        values = []\n",
    "        for match in float_matches:\n",
    "            value = float(match)\n",
    "            # Convert to integer if it's 0.0 or 1.0\n",
    "            if value == 1.0:\n",
    "                values.append(1)\n",
    "            elif value == 0.0:\n",
    "                values.append(0)\n",
    "            else:\n",
    "                values.append(value)  # Keep as float if not 0 or 1\n",
    "                \n",
    "        return values\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error parsing array string: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_mel_spectrogram(audio_path, params):\n",
    "    \"\"\"Loads audio, computes Log-Mel Spectrogram using parameters from config.\"\"\"\n",
    "    try:\n",
    "        # 1. Pull all preprocessing settings out of the params dict\n",
    "        sr                  = params[\"sample_rate\"]              \n",
    "        duration            = params[\"segment_duration_seconds\"] \n",
    "        samples_per_segment = params[\"samples_per_segment\"]      \n",
    "        n_fft               = params[\"n_fft\"]                    \n",
    "        hop_length          = params[\"hop_length\"]               \n",
    "        n_mels              = params[\"n_mels\"]                   \n",
    "\n",
    "        # 2. Load the audio file\n",
    "        #    - resamples to `sr`,  \n",
    "        #    - only reads up to `duration` seconds\n",
    "        y, loaded_sr = librosa.load(\n",
    "            audio_path,\n",
    "            sr=sr,\n",
    "            duration=duration\n",
    "        )\n",
    "\n",
    "        # 3. Pad if shorter than expected duration (librosa pads by default, but explicit is safer)\n",
    "        if len(y) < samples_per_segment:\n",
    "            # 3a. If too short, pad the end with zeros\n",
    "            y = np.pad(y, (0, samples_per_segment - len(y)))\n",
    "        elif len(y) > samples_per_segment:\n",
    "            # 3b. If too long (rare, but just in case), truncate\n",
    "            y = y[:samples_per_segment]\n",
    "\n",
    "        # 4. Compute the Mel spectrogram\n",
    "        melspectrogram = librosa.feature.melspectrogram(\n",
    "            y=y,\n",
    "            sr=sr,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            n_mels=n_mels\n",
    "        )\n",
    "\n",
    "        # 5. Convert power to decibel (log scale), normalizing by the max power\n",
    "        log_melspectrogram = librosa.power_to_db(\n",
    "            melspectrogram,\n",
    "            ref=np.max\n",
    "        )\n",
    "\n",
    "        # 6. Return the final 2D array (shape: [n_mels, time_frames])\n",
    "        return log_melspectrogram\n",
    "\n",
    "    except Exception as e:\n",
    "        # 7. If anything fails (file missing, decode error, etc.), log a warning...\n",
    "        logging.warning(\n",
    "            f\"Could not process file {os.path.basename(audio_path)}: {e}\"\n",
    "        )\n",
    "        # 8. ...and return None so downstream code can skip it gracefully\n",
    "        return None\n",
    "\n",
    "# Load metadata and parse the multi_hot_label column\n",
    "metadata_path = os.path.join(config.PATHS['PROCESSED_DATA_DIR'], 'small_subset_multihot.csv')\n",
    "logging.info(f\"Loading metadata from {metadata_path}\")\n",
    "\n",
    "try:\n",
    "    # Load the CSV file\n",
    "    metadata_df = pd.read_csv(metadata_path, index_col='track_id')\n",
    "    print(\"CSV loaded successfully.\")\n",
    "    print(f\"DataFrame shape: {metadata_df.shape}\")\n",
    "    print(f\"Columns: {metadata_df.columns.tolist()}\")\n",
    "    \n",
    "    # Apply the parser to the multi_hot_label column\n",
    "    if 'multi_hot_label' in metadata_df.columns:\n",
    "        print(\"\\nParsing multi_hot_label column...\")\n",
    "        metadata_df['multi_hot_label'] = metadata_df['multi_hot_label'].apply(parse_numpy_array_string)\n",
    "        \n",
    "        # Show the first few parsed values\n",
    "        print(\"\\nFirst 3 parsed values:\")\n",
    "        for i, val in enumerate(metadata_df['multi_hot_label'].head(3)):\n",
    "            print(f\"{i+1}: {val} (type: {type(val)})\")\n",
    "        \n",
    "        # Verify the parsing worked correctly\n",
    "        total_labels = sum(len(labels) for labels in metadata_df['multi_hot_label'])\n",
    "        print(f\"\\nTotal number of labels across all tracks: {total_labels}\")\n",
    "        print(f\"Average labels per track: {total_labels / len(metadata_df):.2f}\")\n",
    "    \n",
    "    print(\"\\nMetadata processing completed successfully.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to load or parse metadata CSV '{metadata_path}': {e}\", exc_info=True)\n",
    "    print(f\"ERROR: Failed to load or parse {metadata_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhuoyuan/CSprojects/musicClaGen\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(cwd, '../..'))\n",
    "print(PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhuoyuan/CSprojects/musicClaGen/data/processed/fma_features\n"
     ]
    }
   ],
   "source": [
    "print(config.FMA_FEATURES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Test Track ID: 141 ---\n",
      "Audio Path: /home/zhuoyuan/CSprojects/musicClaGen/data/raw/fma_audio/fma_small/000/000141.mp3\n",
      "Label Vector: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Split: training\n",
      "\n",
      "Audio file found. Proceeding with feature extraction...\n",
      "Ensured features directory exists: /home/zhuoyuan/CSprojects/musicClaGen/data/processed/fma_features/fma_small\n",
      "\n",
      "Successfully extracted Mel Spectrogram. Shape: (128, 1876)\n",
      "\n",
      "Saved feature array to: /home/zhuoyuan/CSprojects/musicClaGen/data/processed/fma_features/fma_small/141.npy\n",
      "\n",
      "Manifest Entry for this track:\n",
      "{'track_id': 141, 'feature_path': 'data/processed/fma_features/fma_small/141.npy', 'label_vector': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'split': 'training'}\n",
      "\n",
      "Verification: Loaded saved spectrogram. Shape: (128, 1876)\n",
      "Verification successful.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Choose a Track ID and Extract its Info\n",
    "\n",
    "# --- !!! CHOOSE A TRACK ID TO TEST !!! ---\n",
    "# Pick an ID known to be in your small_subset_multihot.csv (e.g., 2, 5, 10, 140, 141)\n",
    "test_track_id = 141\n",
    "# --- !!! --- !!! --- !!! --- !!! --- !!! ---\n",
    "\n",
    "if test_track_id not in metadata_df.index:\n",
    "    print(f\"ERROR: Test track ID {test_track_id} not found in the loaded metadata.\")\n",
    "else:\n",
    "    # Get the row for the test track\n",
    "    test_row = metadata_df.loc[test_track_id]\n",
    "\n",
    "    # Extract the necessary info\n",
    "    audio_path = test_row['audio_path']\n",
    "    multi_hot_label = test_row['multi_hot_label'] # Now properly parsed as a list of integers\n",
    "    split = test_row['split']\n",
    "\n",
    "    print(f\"--- Processing Test Track ID: {test_track_id} ---\")\n",
    "    print(f\"Audio Path: {audio_path}\")\n",
    "    print(f\"Label Vector: {multi_hot_label}\")\n",
    "    print(f\"Split: {split}\")\n",
    "\n",
    "    # Verify the audio file exists before proceeding\n",
    "    if not os.path.exists(audio_path):\n",
    "        print(f\"\\nERROR: Audio file does not exist at path: {audio_path}\")\n",
    "        # Stop or handle error\n",
    "    else:\n",
    "        print(f\"\\nAudio file found. Proceeding with feature extraction...\")\n",
    "\n",
    "        # --- Create output directory if needed ---\n",
    "        features_output_dir = config.PATHS['FMA_FEATURES_DIR']\n",
    "        os.makedirs(features_output_dir, exist_ok=True)\n",
    "        print(f\"Ensured features directory exists: {features_output_dir}\")\n",
    "\n",
    "        # --- Call the extraction function ---\n",
    "        log_melspec = extract_mel_spectrogram(audio_path, config.PREPROCESSING_PARAMS)\n",
    "\n",
    "        # --- Check result, save feature, and show manifest entry ---\n",
    "        if log_melspec is not None:\n",
    "            print(f\"\\nSuccessfully extracted Mel Spectrogram. Shape: {log_melspec.shape}\")\n",
    "\n",
    "            # Define paths for saving\n",
    "            feature_filename = f\"{test_track_id}.npy\"\n",
    "            absolute_feature_path = os.path.join(features_output_dir, feature_filename)\n",
    "            # Use os.path.relpath to make path relative to PROJECT_ROOT for manifest\n",
    "            relative_feature_path = os.path.join(os.path.relpath(features_output_dir, config.PROJECT_ROOT), feature_filename)\n",
    "            # Replace backslashes on Windows if necessary for consistency\n",
    "            relative_feature_path = relative_feature_path.replace('\\\\', '/')\n",
    "\n",
    "\n",
    "            # Save the feature array\n",
    "            try:\n",
    "                np.save(absolute_feature_path, log_melspec)\n",
    "                print(f\"\\nSaved feature array to: {absolute_feature_path}\")\n",
    "\n",
    "                # Prepare the manifest entry dictionary (what would go in the final CSV)\n",
    "                manifest_entry = {\n",
    "                    'track_id': test_track_id,\n",
    "                    'feature_path': relative_feature_path,\n",
    "                    'label_vector': multi_hot_label,\n",
    "                    'split': split\n",
    "                }\n",
    "\n",
    "                print(\"\\nManifest Entry for this track:\")\n",
    "                print(manifest_entry)\n",
    "\n",
    "                # Optional: Load the saved file back to verify\n",
    "                loaded_spec = np.load(absolute_feature_path)\n",
    "                print(f\"\\nVerification: Loaded saved spectrogram. Shape: {loaded_spec.shape}\")\n",
    "                assert np.array_equal(log_melspec, loaded_spec)\n",
    "                print(\"Verification successful.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\nERROR: Failed to save feature for track {test_track_id}: {e}\")\n",
    "        else:\n",
    "            print(f\"\\nFeature extraction failed for track {test_track_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicClaGen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
